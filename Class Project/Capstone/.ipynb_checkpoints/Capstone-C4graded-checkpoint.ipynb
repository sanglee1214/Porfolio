{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "I need to create a model that will be more accurate than compilation of experts' projections. In order to do that, I need to get the data for the 2015 season along with 2015's preseason projections made by the experts. My goal would be to use the stats from previous season to beat the accuracy score of the experts' projections. My models will be segmented by each positions and perform different regression models such as linear, Lasso, random forest, and few other models for each positions.\n",
    "\n",
    "The current risk I foresee is that some players will get injured, suspended, or retire. Also, I don't have any data on any rookie players. The age needs to be considered. Since players are humans, they cannot perform exactly the same every season.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">JB put the executive summary up top, and give more context to your problem. For example, I have no idea you're taking about fantasy sports till I get to very end.\n",
    "\n",
    ">Position or position group? Are there stats on likelihood of injury by type, or by person to roll into future models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#function that will group rows together\n",
    "def group(iterator, count):\n",
    "    itr = iter(iterator)\n",
    "    while True:\n",
    "        yield tuple([itr.next() for i in range(count)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining for 2015 preseason projections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76 entries, 0 to 75\n",
      "Data columns (total 12 columns):\n",
      "Player             76 non-null object\n",
      "Position           76 non-null object\n",
      "Pass_Attempt       76 non-null object\n",
      "Pass_Completion    76 non-null object\n",
      "Pass_Yards         76 non-null object\n",
      "Pass_Touchdowns    76 non-null object\n",
      "Interceptions      76 non-null object\n",
      "Rush_Attempt       76 non-null object\n",
      "Rush_Yards         76 non-null object\n",
      "Rush_Touchdowns    76 non-null object\n",
      "Fumbles_Lost       76 non-null object\n",
      "Fantasy_Points     76 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#scraping the 2015 QB projection page from fantasypros\n",
    "soupQB = BeautifulSoup(requests.get('https://www.fantasypros.com/nfl/projections/qb.php?year=2015&week=draft').text)\n",
    "\n",
    "#find the body of the table\n",
    "data_QB = soupQB('table')[0].findAll('tbody')[0].text.strip().split()\n",
    "\n",
    "#list of team initials for the entire NFL teams\n",
    "teamList = ['NE','NYJ','MIA','BUF','PIT','BAL','CLE','CIN','HOU','IND',\n",
    "            'JAC','TEN','DEN','KC','SD','OAK','DAL','WAS','NYG','PHI',\n",
    "            'MIN','GB','DET','CHI','NO','TB','ATL','CAR','SF','SEA','ARI','STL','LA']\n",
    "\n",
    "#get rid of the teams\n",
    "data_QB_noTeam = [i for i in data_QB if i not in teamList]\n",
    "\n",
    "#recreate the table from the website into pandas dataframe\n",
    "dfQB = pd.DataFrame(list(group(data_QB_noTeam, 12)))\n",
    "\n",
    "#join first name and last name together into the same column\n",
    "dfQB[0] = dfQB[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "\n",
    "#drop the last name column\n",
    "del dfQB[1]\n",
    "\n",
    "#insert a column for the type of position. For this table, QB.\n",
    "\n",
    "dfQB.insert(1, 'Position', 'QB')\n",
    "\n",
    "#column name for this table\n",
    "column_QB = ['Player','Position','Pass_Attempt','Pass_Completion','Pass_Yards','Pass_Touchdowns','Interceptions',\n",
    "                 'Rush_Attempt','Rush_Yards','Rush_Touchdowns','Fumbles_Lost','Fantasy_Points']\n",
    "\n",
    "#set the columns\n",
    "dfQB.columns = column_QB\n",
    "\n",
    "dfQB.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JB use beautifulsoup specific parser, per above for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152 entries, 0 to 151\n",
      "Data columns (total 10 columns):\n",
      "Player                152 non-null object\n",
      "Position              152 non-null object\n",
      "Rush_Attempt          152 non-null object\n",
      "Rush_Yards            152 non-null object\n",
      "Rush_Touchdowns       152 non-null object\n",
      "Rec                   152 non-null object\n",
      "Receive_Yards         152 non-null object\n",
      "Receive_Touchdowns    152 non-null object\n",
      "Fumbles_Lost          152 non-null object\n",
      "Fantasy_Points        152 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#scraping the 2015 RB projection page from fantasypros\n",
    "soupRB = BeautifulSoup(requests.get('https://www.fantasypros.com/nfl/projections/rb.php?year=2015&week=draft').text)\n",
    "\n",
    "data_RB = soupRB('table')[0].findAll('tbody')[0].text.strip().split()\n",
    "\n",
    "data_RB_noTeam = [i for i in data_RB if i not in teamList]\n",
    "\n",
    "dfRB = pd.DataFrame(list(group(data_RB_noTeam, 10)))\n",
    "\n",
    "dfRB[0] = dfRB[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "\n",
    "del dfRB[1]\n",
    "\n",
    "dfRB.insert(1, 'Position', 'RB')\n",
    "\n",
    "column_RB = ['Player','Position','Rush_Attempt','Rush_Yards','Rush_Touchdowns','Rec','Receive_Yards','Receive_Touchdowns',\n",
    "             'Fumbles_Lost','Fantasy_Points']\n",
    "\n",
    "dfRB.columns = column_RB\n",
    "\n",
    "dfRB.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163 entries, 0 to 162\n",
      "Data columns (total 10 columns):\n",
      "Player                163 non-null object\n",
      "Position              163 non-null object\n",
      "Rush_Attempt          163 non-null object\n",
      "Rush_Yards            163 non-null object\n",
      "Rush_Touchdowns       163 non-null object\n",
      "Rec                   163 non-null object\n",
      "Receive_Yards         163 non-null object\n",
      "Receive_Touchdowns    163 non-null object\n",
      "Fumbles_Lost          163 non-null object\n",
      "Fantasy_Points        163 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 12.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#scraping the RB page\n",
    "soupWR = BeautifulSoup(requests.get('https://www.fantasypros.com/nfl/projections/wr.php?year=2015&week=draft').text)\n",
    "\n",
    "data_WR = soupWR('table')[0].findAll('tbody')[0].text.strip().split()\n",
    "\n",
    "data_WR_noTeam = [i for i in data_WR if i not in teamList]\n",
    "\n",
    "dfWR = pd.DataFrame(list(group(data_WR_noTeam, 10)))\n",
    "\n",
    "dfWR[0] = dfWR[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "\n",
    "del dfWR[1]\n",
    "\n",
    "dfWR.insert(1, 'Position', 'WR')\n",
    "\n",
    "column_WR = ['Player','Position','Rush_Attempt','Rush_Yards','Rush_Touchdowns','Rec','Receive_Yards','Receive_Touchdowns',\n",
    "             'Fumbles_Lost','Fantasy_Points']\n",
    "\n",
    "dfWR.columns = column_WR\n",
    "\n",
    "dfWR.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95 entries, 0 to 94\n",
      "Data columns (total 7 columns):\n",
      "Player                95 non-null object\n",
      "Position              95 non-null object\n",
      "Rec                   95 non-null object\n",
      "Receive_Yards         95 non-null object\n",
      "Receive_Touchdowns    95 non-null object\n",
      "Fumbles_Lost          95 non-null object\n",
      "Fantasy_Points        95 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#scraping the TE page\n",
    "soupTE = BeautifulSoup(requests.get('https://www.fantasypros.com/nfl/projections/te.php?year=2015&week=draft').text)\n",
    "\n",
    "data_TE = soupTE('table')[0].findAll('tbody')[0].text.strip().split()\n",
    "\n",
    "data_TE_noTeam = [i for i in data_TE if i not in teamList]\n",
    "\n",
    "dfTE = pd.DataFrame(list(group(data_TE_noTeam, 7)))\n",
    "\n",
    "dfTE[0] = dfTE[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "\n",
    "del dfTE[1]\n",
    "\n",
    "dfTE.insert(1, 'Position', 'TE')\n",
    "\n",
    "column_TE = ['Player','Position','Rec','Receive_Yards','Receive_Touchdowns','Fumbles_Lost','Fantasy_Points']\n",
    "\n",
    "dfTE.columns = column_TE\n",
    "\n",
    "dfTE.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 6 columns):\n",
      "Player            32 non-null object\n",
      "Position          32 non-null object\n",
      "FGM               32 non-null object\n",
      "FGA               32 non-null object\n",
      "Fumbles_Lost      32 non-null object\n",
      "Fantasy_Points    32 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#scraping the Kickers page\n",
    "soupK = BeautifulSoup(requests.get('https://www.fantasypros.com/nfl/projections/k.php?year=2015&week=draft').text)\n",
    "\n",
    "data_K = soupK('table')[0].findAll('tbody')[0].text.strip().split()\n",
    "\n",
    "data_K_noTeam = [i for i in data_K if i not in teamList]\n",
    "\n",
    "dfK = pd.DataFrame(list(group(data_K_noTeam, 6)))\n",
    "\n",
    "dfK[0] = dfK[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "\n",
    "del dfK[1]\n",
    "\n",
    "dfK.insert(1, 'Position', 'K')\n",
    "\n",
    "column_K = ['Player','Position','FGM','FGA','Fumbles_Lost','Fantasy_Points']\n",
    "\n",
    "dfK.columns = column_K\n",
    "\n",
    "dfK.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Columns | Descriptions| Type\n",
    "|------|------|------|\n",
    "|Player| First and Last name of players| Categorical|\n",
    "|Position| Position of players| Categorical|\n",
    "|Pass_Attempt| number of attempts by passing| Discrete/integer|\n",
    "|Pass_Completion| number of completions by passing| Discrete/integer|\n",
    "|Pass_Yards| number of yards by passing|Discrete/integer|\n",
    "|Pass_Touchdowns| number of touchdowns by passing |Discrete/integer|\n",
    "|Interceptions| number of interceptions|Discrete/integer|\n",
    "|Rush_Attempt| number of rush attempts|Discrete/integer|\n",
    "|Rush_Yards| number of yards by rushing|Discrete/integer|\n",
    "|Rush_Touchdowns| number of touchdowns by rushing|Discrete/integer|\n",
    "|Fumbles_Lost| number of fumbles|Discrete/integer|\n",
    "|Fantasy_Points| total fantasy points|Continuous/float|\n",
    "|Rec| number of receptions|Discrete/integer|\n",
    "|Receive_Yards| number of yards by reception|Discrete/integer|\n",
    "|Receive_Touchdowns| number of touchdowns by reception|Discrete/integer|\n",
    "|FGM| Field Goals Made|Discrete/integer|\n",
    "|FGA| Field Goal Attempts|Discrete/integer|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining for 2015 Actual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Position</th>\n",
       "      <th>Total_Points</th>\n",
       "      <th>Games_Played</th>\n",
       "      <th>Avg_Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cam Newton</td>\n",
       "      <td>CAR</td>\n",
       "      <td>QB</td>\n",
       "      <td>389.1</td>\n",
       "      <td>16</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>NE</td>\n",
       "      <td>QB</td>\n",
       "      <td>343.7</td>\n",
       "      <td>16</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Russell Wilson</td>\n",
       "      <td>SEA</td>\n",
       "      <td>QB</td>\n",
       "      <td>336.4</td>\n",
       "      <td>16</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Blake Bortles</td>\n",
       "      <td>JAC</td>\n",
       "      <td>QB</td>\n",
       "      <td>316.1</td>\n",
       "      <td>16</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td>ARI</td>\n",
       "      <td>QB</td>\n",
       "      <td>309.2</td>\n",
       "      <td>16</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank          Player Team Position Total_Points Games_Played Avg_Points\n",
       "0    1      Cam Newton  CAR       QB        389.1           16       24.3\n",
       "1    2       Tom Brady   NE       QB        343.7           16       21.5\n",
       "2    3  Russell Wilson  SEA       QB        336.4           16       21.0\n",
       "3    4   Blake Bortles  JAC       QB        316.1           16       19.8\n",
       "4    5   Carson Palmer  ARI       QB        309.2           16       19.3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual fantasy points\n",
    "soup_results = BeautifulSoup(requests.get('https://www.fantasypros.com/nfl/reports/leaders/').text)\n",
    "\n",
    "data_results = [i.text for i in soup_results('table')[0].findAll('td')]\n",
    "\n",
    "column_results = ['Rank','Player', 'Team','Position','Total_Points','Games_Played','Avg_Points']\n",
    "dfResults = pd.DataFrame(list(group(data_results,7)),columns=column_results)\n",
    "dfResults.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Postgresql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service `postgresql` already started, use `brew services restart postgresql` to restart.\n",
      "createdb: database creation failed: ERROR:  database \"fantasyfootball\" already exists\n"
     ]
    }
   ],
   "source": [
    "#!brew install postgresql\n",
    "#!brew services stop postgresql\n",
    "!brew services start postgresql\n",
    "!createdb fantasyfootball\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>position</th>\n",
       "      <th>fantasy_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cam Newton</td>\n",
       "      <td>CAR</td>\n",
       "      <td>QB</td>\n",
       "      <td>278.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>NE</td>\n",
       "      <td>QB</td>\n",
       "      <td>281.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russell Wilson</td>\n",
       "      <td>SEA</td>\n",
       "      <td>QB</td>\n",
       "      <td>303.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blake Bortles</td>\n",
       "      <td>JAC</td>\n",
       "      <td>QB</td>\n",
       "      <td>205.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td>ARI</td>\n",
       "      <td>QB</td>\n",
       "      <td>232.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           player team position fantasy_points\n",
       "0      Cam Newton  CAR       QB          278.9\n",
       "1       Tom Brady   NE       QB          281.2\n",
       "2  Russell Wilson  SEA       QB          303.2\n",
       "3   Blake Bortles  JAC       QB          205.5\n",
       "4   Carson Palmer  ARI       QB          232.8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an engine for localhost\n",
    "engine = create_engine('postgresql://:@localhost:5432/fantasyfootball')\n",
    "\n",
    "#lowercase all column names\n",
    "dfQB.columns = [c.lower() for c in dfQB.columns]\n",
    "dfRB.columns = [c.lower() for c in dfRB.columns]\n",
    "dfWR.columns = [c.lower() for c in dfWR.columns]\n",
    "dfTE.columns = [c.lower() for c in dfTE.columns]\n",
    "dfK.columns = [c.lower() for c in dfK.columns]\n",
    "dfResults.columns = [c.lower() for c in dfResults.columns]\n",
    "\n",
    "#write data frames to their own tables\n",
    "#dfQB.to_sql(\"qb\", engine)\n",
    "#dfRB.to_sql(\"rb\", engine)\n",
    "#dfWR.to_sql(\"wr\", engine)\n",
    "#dfTE.to_sql(\"te\", engine)\n",
    "#dfK.to_sql(\"k\", engine)\n",
    "#dfResults.to_sql('results',engine)\n",
    "\n",
    "#connect to the engine\n",
    "connection = engine.connect()\n",
    "\n",
    "#query the player name, team they were on, and projected fantasy points\n",
    "joinedQB = pd.read_sql(\"\"\"\n",
    "                        SELECT results.player,results.team,qb.position,qb.fantasy_points\n",
    "                        FROM results\n",
    "                        JOIN qb \n",
    "                        ON results.player=qb.player\n",
    "                        ;\"\"\",con=engine)\n",
    "\n",
    "joinedRB = pd.read_sql(\"\"\"\n",
    "                        SELECT results.player,results.team,rb.position,rb.fantasy_points\n",
    "                        FROM results\n",
    "                        JOIN rb \n",
    "                        ON results.player=rb.player\n",
    "                        ;\"\"\",con=engine)\n",
    "\n",
    "joinedWR = pd.read_sql(\"\"\"\n",
    "                        SELECT results.player,results.team,wr.position,wr.fantasy_points\n",
    "                        FROM results\n",
    "                        JOIN wr \n",
    "                        ON results.player=wr.player\n",
    "                        ;\"\"\",con=engine)\n",
    "\n",
    "joinedTE = pd.read_sql(\"\"\"\n",
    "                        SELECT results.player,results.team,te.position,te.fantasy_points\n",
    "                        FROM results\n",
    "                        JOIN te \n",
    "                        ON results.player=te.player\n",
    "                        ;\"\"\",con=engine)\n",
    "\n",
    "joinedK = pd.read_sql(\"\"\"\n",
    "                        SELECT results.player,results.team,k.position, k.fantasy_points\n",
    "                        FROM results\n",
    "                        JOIN k \n",
    "                        ON results.player=k.player\n",
    "                        ;\"\"\",con=engine)\n",
    "\n",
    "#concatenate the tables into one big table\n",
    "frames = [joinedQB, joinedRB, joinedWR, joinedTE, joinedK]\n",
    "\n",
    "finalFrame = pd.concat(frames)\n",
    "finalFrame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JB I had problems running the above: is there a way to dynamically create tables if not exists? And .postion typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['position'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-89889187ad0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnewDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msomethingNew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msomethingWeird\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'player'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnewDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'avg_points'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'team_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnewDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'player'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'team_x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'games_played'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'total_points'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fantasy_points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mnewDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"team_x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"team\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"total_points\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"actual\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fantasy_points\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"projected\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2028\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['position'] not in index\""
     ]
    }
   ],
   "source": [
    "#drop names that doesn't exist in the other table and drop duplicates\n",
    "somethingNew = (dfResults.loc[dfResults['player'].isin(finalFrame['player'])])\n",
    "somethingNew = somethingNew.drop_duplicates(['player'],keep='last')\n",
    "\n",
    "somethingWeird = (finalFrame.loc[finalFrame['player'].isin(dfResults['player'])])\n",
    "somethingWeird = somethingWeird.drop_duplicates(['player'], keep='last')\n",
    "somethingWeird['fantasy_points'] = somethingWeird['fantasy_points'].astype(float)\n",
    "\n",
    "#join on the name of players, clean columns, rename some columns\n",
    "newDF = pd.merge(somethingNew, somethingWeird, on='player')\n",
    "newDF.drop(['rank','avg_points','team_y'],axis=1,inplace=True)\n",
    "newDF = newDF[['player','team_x','position','games_played','total_points','fantasy_points']]\n",
    "newDF = newDF.rename(index=str, columns={\"team_x\": \"team\", \"total_points\": \"actual\",\"fantasy_points\":\"projected\"})\n",
    "\n",
    "newDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected vs Actual from the experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'projected'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-8ad2044be422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot projected vs actual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Projected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jb3/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2667\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2669\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'projected'"
     ]
    }
   ],
   "source": [
    "#plot projected vs actual\n",
    "x = newDF.projected.tolist()\n",
    "y = newDF.actual.tolist()\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('Projected')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(newDF['projected'].astype(float),newDF['actual'].astype(float))\n",
    "print\"R-squared:\", r_value**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining for 2014 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URLQB1 = \"http://fftoday.com/stats/playerstats.php?Season=2014&GameWeek=Season&PosID=10&LeagueID=10\"\n",
    "URLQB2 = \"http://fftoday.com/stats/playerstats.php?Season=2014&GameWeek=Season&PosID=10&LeagueID=1&order_by=FFPts&sort_order=DESC&cur_page=1\"\n",
    "\n",
    "#parse the page\n",
    "soupQB1 = BeautifulSoup(requests.get(URLQB1).text)\n",
    "soupQB2 = BeautifulSoup(requests.get(URLQB2).text)\n",
    "\n",
    "#get the data from the first page\n",
    "QB1_data = [[i for i in soupQB1('table')[9].findAll('tr')[0]('tr')[i].text.split()[1:]] \n",
    "               for i in range(len(soupQB1('table')[9].findAll('tr')[0]('tr')))]\n",
    "columnNames = ['First','Last','Team','Games','Comp_P','Att_P','Yards_P','TD_P','INT','ATT_R','Yards_R','TD_R','FPTs','FPTs/G','d']\n",
    "\n",
    "\n",
    "dfQB12014 = pd.DataFrame(QB1_data[2:],columns=columnNames)\n",
    "\n",
    "#merge first name and last name into one column\n",
    "dfQB12014['First'] = dfQB12014[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "del dfQB12014['d']\n",
    "del dfQB12014['Last']\n",
    "\n",
    "#get the data from the second page\n",
    "QB2_data = [[i for i in soupQB2('table')[9].findAll('tr')[0]('tr')[i].text.split()[1:]] \n",
    "               for i in range(len(soupQB2('table')[9].findAll('tr')[0]('tr')))]\n",
    "\n",
    "columnNames = ['First','Last','Team','Games','Comp_P','Att_P','Yards_P','TD_P','INT','ATT_R','Yards_R','TD_R','FPTs','FPTs/G']\n",
    "\n",
    "#merge first name and last name into one column\n",
    "dfQB22014 = pd.DataFrame(QB2_data[2:],columns=columnNames)\n",
    "dfQB22014['First'] = dfQB22014[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "del dfQB22014['Last']\n",
    "\n",
    "#put both tables together\n",
    "dfQB2014 = pd.concat([dfQB12014,dfQB22014])\n",
    "dfQB2014.rename(columns={'First': 'Player'}, inplace=True)\n",
    "\n",
    "#strip the commas\n",
    "dfQB2014['Yards_P'] = dfQB2014['Yards_P'].str.replace(',', '')\n",
    "\n",
    "#convert objects into numeric(integers or floats)\n",
    "dfQB2014 = dfQB2014.convert_objects(convert_numeric=True)\n",
    "\n",
    "#add a new column for completion rate, total yards, total touchdowns, yards per completions\n",
    "dfQB2014['Comp_Rate'] = dfQB2014['Comp_P']/dfQB2014['Att_P']\n",
    "dfQB2014['Total_Yards'] = dfQB2014['Yards_P'] + dfQB2014['Yards_R']\n",
    "dfQB2014['Total_TD'] = dfQB2014['TD_P'] + dfQB2014['TD_R']\n",
    "dfQB2014['Total_Yards_perComp'] = dfQB2014['Total_Yards']/dfQB2014['Comp_P']\n",
    "\n",
    "dfQB2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(dfQB2014.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "somethingNew = (dfResults.loc[dfResults['player'].isin(finalFrame['player'])])\n",
    "somethingNew = somethingNew.drop_duplicates(['player'],keep='last')\n",
    "\n",
    "dfQB2014 = somethingNew.loc[somethingNew['player'].isin(dfQB2014['Player'])]\n",
    "dfQB2014.head()\n",
    "print len(dfQB2014)\n",
    "\n",
    "somethingNew1 = dfQB2014.loc[dfQB2014['player'].isin(somethingNew['player'])]\n",
    "print len(somethingNew1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfQB2014.rename(columns={'Player': 'player'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultQB = pd.merge(dfQB2014, somethingNew, on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultQB.drop(['team','position','games_played','avg_points'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "X_QB = resultQB[['Total_Yards','Total_TD','Total_Yards_perComp']]\n",
    "y_QB = resultQB[['FPTs']]\n",
    "\n",
    "X_QB = X_QB.convert_objects(convert_numeric=True)\n",
    "y_QB = y_QB.convert_objects(convert_numeric=True)\n",
    "\n",
    "\n",
    "X_QB.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "y_QB = y_QB.drop(y_QB.index[[-1]])\n",
    "X_QB.dropna(inplace=True)\n",
    "\n",
    "\n",
    "#Building a model using the train sets and test sets\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model = lm.fit(X_QB, y_QB)\n",
    "predictions = lm.predict(X_QB)\n",
    "target = resultQB[['total_points']].astype(float)\n",
    "target = target.drop(target.index[[-1]])\n",
    "\n",
    "## The line / model\n",
    "plt.scatter(target,predictions)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "#print \"Score:\", model.score(X_QB, target)  \n",
    "print(\"Mean Square Error: %.2f\" % np.mean(((predictions - target) ** 2)/len(X_QB)))\n",
    "print \"R2 value for Lin Reg: %f\" % r2_score(predictions, target) \n",
    "\n",
    "ll = linear_model.LassoCV(alphas=[0.01, 1, 100]).fit(X_QB,y_QB)\n",
    "\n",
    "predictions1 = ll.predict(X_QB)\n",
    "\n",
    "sns.regplot(target,predictions1)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean Square Error: %.2f\" % np.mean((([predictions1] - target) ** 2)/len(predictions1)))\n",
    "print \"R2 value for Lasso: %f\" % r2_score(predictions1, target) \n",
    "#use the 2015 results and try it on the model\n",
    "\n",
    "#use a diff method to model it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "\n",
    "all_scores = []\n",
    "best_score = -1\n",
    "best_depth = 0\n",
    "for i in range(1, 9):\n",
    "    treereg = DecisionTreeRegressor(max_depth=i)\n",
    "    scores = cross_val_score(treereg, X_QB, y_QB, cv=3, n_jobs = -1, scoring='mean_squared_error')\n",
    "    current_score = np.mean(np.sqrt(-scores))\n",
    "    # If the score mean is better than the current best, or best is the default (-1), then update!\n",
    "    if current_score < best_score or best_score == -1:\n",
    "        best_score = current_score\n",
    "        best_depth = i\n",
    "    # store to plot anyway!\n",
    "    all_scores.append(current_score)\n",
    "    \n",
    "print \"Best score: %s\" % best_score\n",
    "print \"Best depth: %s\" % best_depth\n",
    "\n",
    "# now actually fit the model\n",
    "treereg = DecisionTreeRegressor(max_depth=best_depth)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_QB, y_QB, test_size=0.3)\n",
    "treereg.fit(X_QB, y_QB)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, 9), all_scores)\n",
    "plt.xlabel('x=max tree depth')\n",
    "plt.show()\n",
    "\n",
    "preds = treereg.predict(X_QB)\n",
    "\n",
    "sns.regplot(target,preds)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "print \"R2 value for decision tree: %f\" % r2_score(preds, target) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rfScore = cross_val_score(rf,X_QB,y_QB,cv=3,verbose=True,n_jobs=-1)\n",
    "rf.fit(X_QB, y_QB)\n",
    "\n",
    "preds_rf = rf.predict(X_QB)\n",
    "\n",
    "sns.regplot(target,preds_rf)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "print \"R2 value for Random Forest: %f\" % r2_score(preds_rf, target) \n",
    "\n",
    "#print predictions, predictions1,preds,preds_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that the R^2 values are so good is because fantasy points are derived from the stats. You can also see that from the heatmap that they have strong positive relationship between fantasy points and yards/touchdowns. I need to build different models and test it against 2015 results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URLRB1 = \"http://fftoday.com/stats/playerstats.php?Season=2014&GameWeek=Season&PosID=20&LeagueID=0\"\n",
    "URLRB2 = \"http://fftoday.com/stats/playerstats.php?Season=2014&GameWeek=Season&PosID=20&LeagueID=1&order_by=FFPts&sort_order=DESC&cur_page=3\"\n",
    "\n",
    "#parse the page\n",
    "soupRB1 = BeautifulSoup(requests.get(URLRB1).text)\n",
    "soupRB2 = BeautifulSoup(requests.get(URLRB2).text)\n",
    "\n",
    "RB1_data = [[i for i in soupRB1('table')[9].findAll('tr')[0]('tr')[i].text.split()[1:]] \n",
    "               for i in range(len(soupRB1('table')[9].findAll('tr')[0]('tr')))]\n",
    "columnNames = ['First','Last','Team','Games', 'Att_Rush','Yards_Rush','TD_Rush','Target','RecNum','Yards_Rec','TD_Rec','FPTs','FPTs/G']\n",
    "\n",
    "\n",
    "dfRB12014 = pd.DataFrame(RB1_data[2:],columns=columnNames)\n",
    "\n",
    "dfRB12014['First'] = dfRB12014[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "del dfRB12014['Last']\n",
    "\n",
    "RB2_data = [[i for i in soupRB2('table')[9].findAll('tr')[0]('tr')[i].text.split()[1:]] \n",
    "               for i in range(len(soupRB2('table')[9].findAll('tr')[0]('tr')))]\n",
    "\n",
    "dfRB22014 = pd.DataFrame(RB2_data[2:],columns=columnNames)\n",
    "dfRB22014['First'] = dfRB22014[[0,1]].apply(lambda x: ' '.join(x),axis=1)\n",
    "del dfRB22014['Last']\n",
    "\n",
    "dfRB2014 = pd.concat([dfRB12014,dfRB22014])\n",
    "dfRB2014.rename(columns={'First': 'Player'}, inplace=True)\n",
    "dfRB2014['Yards_Rush'] = dfRB2014['Yards_Rush'].str.replace(',','')\n",
    "\n",
    "#convert objects into numeric(integers or floats)\n",
    "dfRB2014 = dfRB2014.convert_objects(convert_numeric=True)\n",
    "\n",
    "dfRB2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfRB2014.rename(columns={'Player': 'player'}, inplace=True)\n",
    "resultRB = pd.merge(dfRB2014, somethingNew, on='player')\n",
    "resultRB = resultRB.convert_objects(convert_numeric=True)\n",
    "resultRB['Total_Yards'] = resultRB['Yards_Rush'] + resultRB['Yards_Rec']\n",
    "resultRB['Total_TD'] = resultRB['TD_Rush'] + resultRB['TD_Rec']\n",
    "resultRB['Att'] = resultRB['Att_Rush'] + resultRB['RecNum']\n",
    "resultRB['Total_Yards_perComp'] = resultRB['Total_Yards'] / resultRB['Att']\n",
    "resultRB.drop(['team','position','games_played','avg_points'],inplace=True,axis=1)\n",
    "resultRB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultRB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-82972c497a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_RB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresultRB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Yards'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Total_TD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Total_Yards_perComp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_RB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresultRB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FPTs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#X_RB = X_RB.convert_objects(convert_numeric=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#y_RB = y_RB.convert_objects(convert_numeric=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resultRB' is not defined"
     ]
    }
   ],
   "source": [
    "X_RB = resultRB[['Total_Yards','Total_TD','Total_Yards_perComp']]\n",
    "y_RB = resultRB[['FPTs']]\n",
    "\n",
    "#X_RB = X_RB.convert_objects(convert_numeric=True)\n",
    "#y_RB = y_RB.convert_objects(convert_numeric=True)\n",
    "\n",
    "X_RB.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "y_RB = y_RB.drop(y_RB.index[[-1]])\n",
    "y_RB = y_RB.drop(y_RB.index[[-1]])\n",
    "X_RB.dropna(inplace=True)\n",
    "\n",
    "#Building a model using the train sets and test sets\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model = lm.fit(X_RB, y_RB)\n",
    "predictions = lm.predict(X_RB)\n",
    "target = resultRB[['total_points']].astype(float)\n",
    "target = target.drop(target.index[[-1]])\n",
    "target = target.drop(target.index[[-1]])\n",
    "\n",
    "## The line / model\n",
    "plt.scatter(target,predictions)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "#print \"Score:\", model.score(X_QB, target)  \n",
    "print(\"Mean Square Error: %.2f\" % np.mean(((predictions - target) ** 2)/len(X_QB)))\n",
    "print \"R2 value: %f\" % r2_score(predictions, target) \n",
    "\n",
    "ll = linear_model.LassoCV(alphas=[0.01, 1, 100]).fit(X_RB,y_RB)\n",
    "\n",
    "predictions1 = ll.predict(X_RB)\n",
    "\n",
    "sns.regplot(target,predictions1)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean Square Error: %.2f\" % np.mean((([predictions1] - target) ** 2)/len(predictions1)))\n",
    "print \"R2 value: %f\" % r2_score(predictions1, target) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "best_score = -1\n",
    "best_depth = 0\n",
    "for i in range(1, 9):\n",
    "    treereg = DecisionTreeRegressor(max_depth=i)\n",
    "    scores = cross_val_score(treereg, X_RB, y_RB, cv=3, n_jobs = -1, scoring='mean_squared_error')\n",
    "    current_score = np.mean(np.sqrt(-scores))\n",
    "    # If the score mean is better than the current best, or best is the default (-1), then update!\n",
    "    if current_score < best_score or best_score == -1:\n",
    "        best_score = current_score\n",
    "        best_depth = i\n",
    "    # store to plot anyway!\n",
    "    all_scores.append(current_score)\n",
    "    \n",
    "print \"Best score: %s\" % best_score\n",
    "print \"Best depth: %s\" % best_depth\n",
    "\n",
    "# now actually fit the model\n",
    "treereg = DecisionTreeRegressor(max_depth=best_depth)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_QB, y_QB, test_size=0.3)\n",
    "treereg.fit(X_RB, y_RB)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, 9), all_scores)\n",
    "plt.xlabel('x=max tree depth')\n",
    "plt.show()\n",
    "\n",
    "preds = treereg.predict(X_QB)\n",
    "\n",
    "sns.regplot(target,preds[:49])\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "print \"R2 value: %f\" % r2_score(preds[:49], target) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rfScore = cross_val_score(rf,X_RB,y_RB,cv=3,verbose=True,n_jobs=-1)\n",
    "rf.fit(X_RB, y_RB)\n",
    "\n",
    "preds_rf = rf.predict(X_RB)\n",
    "\n",
    "sns.regplot(target,preds_rf)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "print \"R2 value: %f\" % r2_score(preds_rf, target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared values for all the models that I have tested on the quarter backs and running backs tell me that the stats from previous years cannot predict better than the expert's preseason predictions. There are a lot more factors than purely stats that contribute to the fantasy points at the end of the season. To make a better model, I need to investigate further into how experts are coming up with their predictions, and include other features such as team ranking injuries,and other stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my own models were not successful, I will use the expert predictions to cluster players into tiers to recommend who you should draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalFrame['fantasy_points'] = finalFrame['fantasy_points'].astype(float)\n",
    "finalFrame.sort_values(by='fantasy_points',axis=0,ascending=False,inplace=True)\n",
    "finalFrame.reset_index(inplace=True,drop=True)\n",
    "#finalFrame.drop(['index'],axis=1,inplace=True)\n",
    "finalFrame.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "finalFrame['Rank'] = finalFrame.index + 1\n",
    "\n",
    "data = finalFrame[['Rank','fantasy_points']]\n",
    "data = data.as_matrix().astype(\"float32\", copy = False)\n",
    "\n",
    "stscaler = StandardScaler().fit(data)\n",
    "data = stscaler.transform(data)\n",
    "\n",
    "dataDF = pd.DataFrame(data)\n",
    "plt.scatter(dataDF[1],dataDF[0])\n",
    "\n",
    "dbsc = DBSCAN(eps = .1, min_samples =1).fit(data)\n",
    "labels = dbsc.labels_\n",
    "core_samples = np.zeros_like(labels, dtype = bool)\n",
    "core_samples[dbsc.core_sample_indices_] = True\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "clusters = [data[labels == i] for i in xrange(n_clusters_)]\n",
    "\n",
    "unique_labels = set(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = data[class_member_mask & core_samples]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = data[class_member_mask & ~core_samples]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n",
    "\n",
    "print \"DBSCAN does not give a sufficient number of clusters since the points are so close to each other.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "kmeansDF = finalFrame.iloc[:,3:]\n",
    "kmean = KMeans(n_clusters=100, random_state=10) \n",
    "\n",
    "kmean.fit(kmeansDF)\n",
    "\n",
    "clusters = {}\n",
    "n = 0\n",
    "for item in kmean.labels_:\n",
    "    if item in clusters:\n",
    "        clusters[item].append(finalFrame.iloc[n,:])\n",
    "    else:\n",
    "        clusters[item] = [finalFrame.iloc[n,:]]\n",
    "    n +=1\n",
    "\n",
    "recomList = []\n",
    "clusterList = []\n",
    "for item in clusters:\n",
    "    #print \"Cluster \", item\n",
    "    for i in clusters[item]:\n",
    "        clusterList.append(item)\n",
    "        recomList.append(i)\n",
    "\n",
    "recomDF = pd.DataFrame(recomList)\n",
    "recomDF['cluster'] = clusterList\n",
    "recomDF['fantasy_points'] = recomDF['fantasy_points'].astype(float)\n",
    "#print recomDF\n",
    "#recomDF = recomDF.groupby(['cluster','player']).mean()\n",
    "#recomDF.sort(['fantasy_points'], ascending=False, inplace=True)\n",
    "fantasyP = recomDF['fantasy_points'].groupby(recomDF['cluster']).mean()\n",
    "#print len(fantasyP)\n",
    "\n",
    "mydict = {}\n",
    "for x in range(len(recomDF)):\n",
    "    currentcluster = recomDF.iloc[x,5]\n",
    "    currentvalue = recomDF.iloc[x,[0,2]]\n",
    "    mydict.setdefault(currentcluster, [])\n",
    "    mydict[currentcluster].append(currentvalue)\n",
    "\n",
    "dictDF = pd.DataFrame([[key,value] for key,value in mydict.items()],columns=[\"cluster\",\"player\"])\n",
    "dictDF['fantasy_points'] = fantasyP\n",
    "\n",
    "qbList = []\n",
    "rbList = []\n",
    "teList = []\n",
    "wrList = []\n",
    "kList = []\n",
    "for i in dictDF.player:\n",
    "    qbList.append([y[0] for y in i if y[1] == 'QB'])\n",
    "    rbList.append([y[0] for y in i if y[1] == 'RB'])\n",
    "    wrList.append([y[0] for y in i if y[1] == 'WR'])\n",
    "    teList.append([y[0] for y in i if y[1] == 'TE'])\n",
    "    kList.append([y[0] for y in i if y[1] == 'K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictDF.sort_values(by='fantasy_points',axis=0,ascending=False,inplace=True)\n",
    "print dictDF\n",
    "print \"I have no idea why this doesn't work. The exact same code worked an hour ago.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was too tired by this point, but the data frame aboves gives recommendations for each rounds of fantasy draft. If a player runs out in the first rank, then you should pick players from the next rank. If you look at the players, there seems to be some anomalies in draft recommendations. This is possibly due to the way the data is clustered. K means is best for hyper spherical data whereas the data that I feed into K-means clustering algorithm is not hyper-spherical. I need to look into a different means of clustering to best group the players. Then, I will compare the draft recommendations to the actual results from the 2015 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "from pylab import *\n",
    "\n",
    "samples = finalFrame.iloc[:,3:]\n",
    "gmix = mixture.GMM(n_components=50, covariance_type='full')\n",
    "gmix.fit(samples)\n",
    "#print gmix.means_\n",
    "tiers = gmix.predict(samples)\n",
    "#colors = ['r' if i==0 else 'g' for i in gmix.predict(samples)]\n",
    "ax = plt.gca()\n",
    "\n",
    "from matplotlib import cm\n",
    "from numpy import linspace\n",
    "\n",
    "start = 0.0\n",
    "stop = 1.0\n",
    "number_of_lines= 1000\n",
    "cm_subsection = linspace(start, stop, number_of_lines) \n",
    "\n",
    "colors = [ cm.jet(x) for x in cm_subsection ]\n",
    "ax.scatter(samples.iloc[:,0], samples.iloc[:,1], c=colors, alpha=0.8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GaussDF = finalFrame\n",
    "#GaussDF.drop('Rank',axis=1,inplace=True)\n",
    "GaussDF['Tier'] = tiers\n",
    "fantasyP2 = GaussDF['fantasy_points'].groupby(GaussDF['Tier']).mean()\n",
    "\n",
    "mydict2 = {}\n",
    "for x in range(len(GaussDF)):\n",
    "    currentTier = GaussDF.iloc[x,5]\n",
    "    currentvalue = GaussDF.iloc[x,[0,2]]\n",
    "    mydict2.setdefault(currentTier, [])\n",
    "    mydict2[currentTier].append(currentvalue)\n",
    "\n",
    "\n",
    "dictDF2 = pd.DataFrame([[key,value] for key,value in mydict2.items()],columns=[\"Tier\",\"player\"])\n",
    "dictDF2['fantasy_points'] = [x for x in fantasyP2 if x != np.nan]\n",
    "dictDF2.sort_values(by='fantasy_points',axis=0,ascending=False,inplace=True)\n",
    "print dictDF2\n",
    "print \"This is my final draft recommendation. The players in the same tier should be worth the same. For example,\"\n",
    "print \"Andrew Luck from the Tier 19 should perform similar to Aaron Rodgers. If a player picks Andrew Luck as their\"\n",
    "print \"first pick, you can pick Aaron Rodgers since they are supposed to perform similarly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "The goal of this project is to provide recommendations for your NFL fantasy league. My initial idea was to scrap data from a website that gives each NFL offensive player's statistics from 2014 and use that data to come up with best predictive model to pick the best players. The success criteria of the model is to have a better R^2 value than the expert's projections. The expert's projections were scraped from fantasypros.com. The R^2 value from the experts compared to the actual results was 0.6. Therefore, I needed to come up with a model that gives better R^2 value than 0.6. The models that I tried was linear regression, Lasso linear regression, Decision Tree Regressor with optimized depth, and Random Forest Regressor. However, the R^2 value for the QB position and RB position was significantly weaker than the expert's projection. The shortcomings from the model comes from less lack variety in the features. There are more factors that will affect the player's performance in the next season. Therefore, it is safe to conclude that the previous year's performances cannot predict better results on player's performance on next year's season. Next steps that I took was to take the projections made by the experts and cluster them into ranks or tiers. The idea was to group players with similar qualities into ranks or tiers. Since the draft order is sequential for league players, it is easier to distinguish whether one player predicted to perform similarly to other players. I used three clustering algorithms: DBSCAN, K-Means, and Gaussian Mixture Model. DBSCAN did not perform very well since all the points were so close to each other. K-Means clustering did not work well since the type of data that I had was not hyper-spherical. Gaussian Mixture Model successfully grouped these players into tiers of similar qualities. In order to improve my original predictive models, I need to have different features such as team ranking, injuries, and research other unknown features that might be impactful. More research and analysis on how other experts predict the next year's performances in order to select the best features for the model. For the clustering algorithms, having more features would cluster them into groups more evenly. Splitting the clustering by different positions would provide a nice insight on how you should draft players as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JB DBSCAN can work, distance is relative, so you have to optimize your radius and min_points inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "MG:\n",
    "\n",
    "Part 2 Score |  22/21\n",
    "-------|-----\n",
    "Identify: Articulate Problem Statement/Specific goals & success criteria        |        3\n",
    "Identify: Outline proposed methods & models        | 3 \n",
    "Parse: Identify risks & assumptions                | 3\n",
    "Parse: Create local PostgreSQL database            | 3\n",
    "Parse: Query, Sort, & Clean Data                | 3\n",
    "Parse: Create a Data Dictionary                | 3\n",
    "Mine: Perform & summarize EDA                | 3\n",
    "Bonus! Refine: Explain how you intend to tune & evaluate your results | 1\n",
    "\n",
    "Part 3 Score |  12/15\n",
    "-------|-----\n",
    "Mine: Correlate data & run statistical analysis        | 3\n",
    "Refine: Plot data w visual analysis                | 3\n",
    "Model: Run model on data (train subset as needed)            | 2\n",
    "Present: Summarize approach & initial results                | 2\n",
    "Present: Describe successes, setbacks, & lessons learned  | 2\n",
    "Bonus: Use 2 or more dataviz tools | 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C4 Score: | 20/30\n",
    "------------|---------\n",
    "Identify: Create executive summary\t\t\t\t| 3\n",
    "Acquire: Demonstrate how you imported, queried, and sorted your data\t\t\t| 3\n",
    "Parse: Identify any outliers, define variables\t\t\t\t| 2\n",
    "Mine: Perform statistical analysis, correlate data\t\t\t\t| 2\n",
    "Refine: Describe and plot your data\t\t\t\t| 1\n",
    "Model: Perform model (train subset as needed)\t\t\t\t| 2\n",
    "Model: Tune and evaluate model\t\t\t\t| 2\n",
    "Present: Discuss model selection and implementation process\t\t\t\t|2\n",
    "Present: Interpret findings and relate to goals/criteria\t\t\t\t| 2\n",
    "Present: Create recommendations for stakeholders & summarize next steps\t\t|\t\t1\n",
    "Bonus! Deploy: Discuss how to deploy model in production environment | 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
